{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Erasani_selfstudy10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "q0ooRVtqG2kW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KoYIcv5rG45-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Chapter 11\n",
        "# Machine Learning "
      ]
    },
    {
      "metadata": {
        "id": "AMgLuJaRD8ht",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import math, random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WUh01n8fEOK-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def split_data(data, prob):\n",
        "    \"\"\"split data into fractions [prob, 1 - prob]\"\"\"\n",
        "    results = [], []\n",
        "    for row in data:\n",
        "        results[0 if random.random() < prob else 1].append(row)\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2XV6bw53EdW2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_test_split(x, y, test_pct):\n",
        "    data = list(zip(x, y))                        # pair corresponding values\n",
        "    train, test = split_data(data, 1 - test_pct)  # split the dataset of pairs\n",
        "    x_train, y_train = list(zip(*train))          # magical un-zip trick\n",
        "    x_test, y_test = list(zip(*test))\n",
        "    return x_train, x_test, y_train, y_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hdloonzqFLqo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "318c317a-3142-4260-aab1-49d49a2bd5ee"
      },
      "cell_type": "code",
      "source": [
        "def accuracy(tp, fp, fn, tn):\n",
        "    correct = tp + tn\n",
        "    total = tp + fp + fn + tn\n",
        "    return correct / total\n",
        "print (accuracy(70, 4930, 13930, 981070))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.98114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TILZC1hdF4-q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "babe7d79-1664-4c3e-e329-b7e8dc20cf48"
      },
      "cell_type": "code",
      "source": [
        "def precision(tp, fp, fn, tn):\n",
        "    return tp / (tp + fp)\n",
        "print (precision(70, 4930, 13930, 981070))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "60j0TiLvGC0a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f37e0b2a-b08e-4769-e96d-9f8c0a777012"
      },
      "cell_type": "code",
      "source": [
        "def recall(tp, fp, fn, tn):\n",
        "  return tp / (tp + fn)\n",
        "print (recall(70, 4930, 13930, 981070))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K4uMZA6zGLK7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def f1_score(tp, fp, fn, tn):\n",
        "  p = precision(tp, fp, fn, tn)\n",
        "  r = recall(tp, fp, fn, tn)\n",
        "  return 2 * p * r / (p + r)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K2TzKjL1GZLD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22e6b37f-11b2-4a38-80ab-4f5d0a47b940"
      },
      "cell_type": "code",
      "source": [
        "print(\"f1_score(70, 4930, 13930, 981070)\", f1_score(70, 4930, 13930, 981070))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1_score(70, 4930, 13930, 981070) 0.00736842105263158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xmAXxEiMGfzk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Chapter 13\n",
        "# Naive Bayes "
      ]
    },
    {
      "metadata": {
        "id": "sWb-3a3gG1Dl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter, defaultdict\n",
        "import math, random, re, glob\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ascxPLFEHHkW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokenize(message):\n",
        "    message = message.lower()                       # convert to lowercase\n",
        "    all_words = re.findall(\"[a-z0-9']+\", message)   # extract the words\n",
        "    return set(all_words)                           # remove duplicates\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lzYb19yZHPwe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def count_words(training_set):\n",
        "    \"\"\"training set consists of pairs (message, is_spam)\"\"\"\n",
        "    counts = defaultdict(lambda: [0, 0])\n",
        "    for message, is_spam in training_set:\n",
        "        for word in tokenize(message):\n",
        "            counts[word][0 if is_spam else 1] += 1\n",
        "    return counts\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hPiFO4BxHTnO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def word_probabilities(counts, total_spams, total_non_spams, k=0.5):\n",
        "    \"\"\"turn the word_counts into a list of triplets\n",
        "    w, p(w | spam) and p(w | ~spam)\"\"\"\n",
        "    return [(w,\n",
        "             (spam + k) / (total_spams + 2 * k),\n",
        "             (non_spam + k) / (total_non_spams + 2 * k))\n",
        "             for w, (spam, non_spam) in counts.items()]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pMEG1oUmHWSu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def spam_probability(word_probs, message):\n",
        "    message_words = tokenize(message)\n",
        "    log_prob_if_spam = log_prob_if_not_spam = 0.0\n",
        "\n",
        "    for word, prob_if_spam, prob_if_not_spam in word_probs:\n",
        "\n",
        "        # for each word in the message,\n",
        "        # add the log probability of seeing it\n",
        "        if word in message_words:\n",
        "            log_prob_if_spam += math.log(prob_if_spam)\n",
        "            log_prob_if_not_spam += math.log(prob_if_not_spam)\n",
        "\n",
        "        # for each word that's not in the message\n",
        "        # add the log probability of _not_ seeing it\n",
        "        else:\n",
        "            log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
        "            log_prob_if_not_spam += math.log(1.0 - prob_if_not_spam)\n",
        "\n",
        "    prob_if_spam = math.exp(log_prob_if_spam)\n",
        "    prob_if_not_spam = math.exp(log_prob_if_not_spam)\n",
        "    return prob_if_spam / (prob_if_spam + prob_if_not_spam)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tosr3HWLHaoX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NaiveBayesClassifier:\n",
        "\n",
        "    def __init__(self, k=0.5):\n",
        "        self.k = k\n",
        "        self.word_probs = []\n",
        "\n",
        "    def train(self, training_set):\n",
        "\n",
        "        # count spam and non-spam messages\n",
        "        num_spams = len([is_spam\n",
        "                         for message, is_spam in training_set\n",
        "                         if is_spam])\n",
        "        num_non_spams = len(training_set) - num_spams\n",
        "\n",
        "        # run training data through our \"pipeline\"\n",
        "        word_counts = count_words(training_set)\n",
        "        self.word_probs = word_probabilities(word_counts,\n",
        "                                             num_spams,\n",
        "                                             num_non_spams,\n",
        "                                             self.k)\n",
        "\n",
        "    def classify(self, message):\n",
        "        return spam_probability(self.word_probs, message)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fS-VUUC7HfDn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_subject_data(path):\n",
        "\n",
        "    data = []\n",
        "\n",
        "    # regex for stripping out the leading \"Subject:\" and any spaces after it\n",
        "    subject_regex = re.compile(r\"^Subject:\\s+\")\n",
        "\n",
        "    # glob.glob returns every filename that matches the wildcarded path\n",
        "    for fn in glob.glob(path):\n",
        "        is_spam = \"ham\" not in fn\n",
        "\n",
        "        with open(fn,'r',encoding='ISO-8859-1') as file:\n",
        "            for line in file:\n",
        "                if line.startswith(\"Subject:\"):\n",
        "                    subject = subject_regex.sub(\"\", line).strip()\n",
        "                    data.append((subject, is_spam))\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PEOXGeGsIODw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def p_spam_given_word(word_prob):\n",
        "    word, prob_if_spam, prob_if_not_spam = word_prob\n",
        "    return prob_if_spam / (prob_if_spam + prob_if_not_spam)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fmJKC-iPIQ0Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_and_test_model(path):\n",
        "\n",
        "    data = get_subject_data(path)\n",
        "    random.seed(0)      # just so you get the same answers as me\n",
        "    train_data, test_data = split_data(data, 0.75)\n",
        "\n",
        "    classifier = NaiveBayesClassifier()\n",
        "    classifier.train(train_data)\n",
        "\n",
        "    classified = [(subject, is_spam, classifier.classify(subject))\n",
        "              for subject, is_spam in test_data]\n",
        "\n",
        "    counts = Counter((is_spam, spam_probability > 0.5) # (actual, predicted)\n",
        "                     for _, is_spam, spam_probability in classified)\n",
        "\n",
        "    print(counts)\n",
        "\n",
        "    classified.sort(key=lambda row: row[2])\n",
        "    spammiest_hams = list(filter(lambda row: not row[1], classified))[-5:]\n",
        "    hammiest_spams = list(filter(lambda row: row[1], classified))[:5]\n",
        "\n",
        "    print(\"spammiest_hams\", spammiest_hams)\n",
        "    print(\"hammiest_spams\", hammiest_spams)\n",
        "\n",
        "    words = sorted(classifier.word_probs, key=p_spam_given_word)\n",
        "\n",
        "    spammiest_words = words[-5:]\n",
        "    hammiest_words = words[:5]\n",
        "\n",
        "    print(\"spammiest_words\", spammiest_words)\n",
        "    print(\"hammiest_words\", hammiest_words)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LTmB0aInIhj4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2e574032-ad19-4ecf-e725-be9f18c845be"
      },
      "cell_type": "code",
      "source": [
        "train_and_test_model(r\"/home/joel/src/spam/*/*\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter()\n",
            "spammiest_hams []\n",
            "hammiest_spams []\n",
            "spammiest_words []\n",
            "hammiest_words []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rk1vxzFWIwmD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Chapter 17\n",
        "# Decision Trees "
      ]
    },
    {
      "metadata": {
        "id": "xc2TmaNxI2GJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter, defaultdict\n",
        "from functools import partial\n",
        "import math, random\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ipOkp0NJkRp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def entropy(class_probabilities):\n",
        "    \"\"\"given a list of class probabilities, compute the entropy\"\"\"\n",
        "    return sum(-p * math.log(p, 2) for p in class_probabilities if p)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eOs-gxTNJmRZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def class_probabilities(labels):\n",
        "    total_count = len(labels)\n",
        "    return [count / total_count\n",
        "            for count in Counter(labels).values()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p8GqwV3HJrmb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_entropy(labeled_data):\n",
        "    labels = [label for _, label in labeled_data]\n",
        "    probabilities = class_probabilities(labels)\n",
        "    return entropy(probabilities)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_MSZCnihJtva",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def partition_entropy(subsets):\n",
        "    \"\"\"find the entropy from this partition of data into subsets\"\"\"\n",
        "    total_count = sum(len(subset) for subset in subsets)\n",
        "\n",
        "    return sum( data_entropy(subset) * len(subset) / total_count\n",
        "                for subset in subsets )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1kUNGDeAJ1Na",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputs = [\n",
        "({'level':'Senior', 'lang':'Java', 'tweets':'no', 'phd':'no'}, False),\n",
        "({'level':'Senior', 'lang':'Java', 'tweets':'no', 'phd':'yes'}, False),\n",
        "({'level':'Mid', 'lang':'Python', 'tweets':'no', 'phd':'no'}, True),\n",
        "({'level':'Junior', 'lang':'Python', 'tweets':'no', 'phd':'no'}, True),\n",
        "({'level':'Junior', 'lang':'R', 'tweets':'yes', 'phd':'no'}, True),\n",
        "({'level':'Junior', 'lang':'R', 'tweets':'yes', 'phd':'yes'}, False),\n",
        "({'level':'Mid', 'lang':'R', 'tweets':'yes', 'phd':'yes'}, True),\n",
        "({'level':'Senior', 'lang':'Python', 'tweets':'no', 'phd':'no'}, False),\n",
        "({'level':'Senior', 'lang':'R', 'tweets':'yes', 'phd':'no'}, True),\n",
        "({'level':'Junior', 'lang':'Python', 'tweets':'yes', 'phd':'no'}, True),\n",
        "({'level':'Senior', 'lang':'Python', 'tweets':'yes', 'phd':'yes'}, True),\n",
        "({'level':'Mid', 'lang':'Python', 'tweets':'no', 'phd':'yes'}, True),\n",
        "({'level':'Mid', 'lang':'Java', 'tweets':'yes', 'phd':'no'}, True),\n",
        "({'level':'Junior', 'lang':'Python', 'tweets':'no', 'phd':'yes'}, False)\n",
        "]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mb35UO1IJ8dU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def group_by(items, key_fn):\n",
        "    \"\"\"returns a defaultdict(list), where each input item\n",
        "    is in the list whose key is key_fn(item)\"\"\"\n",
        "    groups = defaultdict(list)\n",
        "    for item in items:\n",
        "        key = key_fn(item)\n",
        "        groups[key].append(item)\n",
        "    return groups"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kiZwMNuzKB71",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def partition_by(inputs, attribute):\n",
        "    \"\"\"returns a dict of inputs partitioned by the attribute\n",
        "    each input is a pair (attribute_dict, label)\"\"\"\n",
        "    return group_by(inputs, lambda x: x[0][attribute])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kMrG-V_AKEJ8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def partition_entropy_by(inputs,attribute):\n",
        "    \"\"\"computes the entropy corresponding to the given partition\"\"\"\n",
        "    partitions = partition_by(inputs, attribute)\n",
        "    return partition_entropy(partitions.values())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ahyWEWkKIDt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d2378c63-5039-43e4-929a-905b937ff5e3"
      },
      "cell_type": "code",
      "source": [
        "for key in ['level','lang','tweets','phd']:\n",
        "  print (key, partition_entropy_by(inputs, key))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "level 0.6935361388961919\n",
            "lang 0.8601317128547441\n",
            "tweets 0.7884504573082896\n",
            "phd 0.8921589282623617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eCQRLuYvKLJA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "senior_inputs = [(input, label)\n",
        "                 for input, label in inputs if input[\"level\"] == \"Senior\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n60Y87lMKSc4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "df62f5d8-11dc-4c7b-b982-2600972766ab"
      },
      "cell_type": "code",
      "source": [
        "for key in ['lang', 'tweets', 'phd']:\n",
        "  print (key, partition_entropy_by(senior_inputs, key))\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lang 0.4\n",
            "tweets 0.0\n",
            "phd 0.9509775004326938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DYKji7vyKXiz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classify(tree, input):\n",
        "    \"\"\"classify the input using the given decision tree\"\"\"\n",
        "\n",
        "    # if this is a leaf node, return its value\n",
        "    if tree in [True, False]:\n",
        "        return tree\n",
        "\n",
        "    # otherwise find the correct subtree\n",
        "    attribute, subtree_dict = tree\n",
        "\n",
        "    subtree_key = input.get(attribute)  # None if input is missing attribute\n",
        "\n",
        "    if subtree_key not in subtree_dict: # if no subtree for key,\n",
        "        subtree_key = None              # we'll use the None subtree\n",
        "\n",
        "    subtree = subtree_dict[subtree_key] # choose the appropriate subtree\n",
        "    return classify(subtree, input)     # and use it to classify the input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PHCSpmOYKeP6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_tree_id3(inputs, split_candidates=None):\n",
        "\n",
        "    # if this is our first pass,\n",
        "    # all keys of the first input are split candidates\n",
        "    if split_candidates is None:\n",
        "        split_candidates = inputs[0][0].keys()\n",
        "\n",
        "    # count Trues and Falses in the inputs\n",
        "    num_inputs = len(inputs)\n",
        "    num_trues = len([label for item, label in inputs if label])\n",
        "    num_falses = num_inputs - num_trues\n",
        "\n",
        "    if num_trues == 0:                  # if only Falses are left\n",
        "        return False                    # return a \"False\" leaf\n",
        "\n",
        "    if num_falses == 0:                 # if only Trues are left\n",
        "        return True                     # return a \"True\" leaf\n",
        "\n",
        "    if not split_candidates:            # if no split candidates left\n",
        "        return num_trues >= num_falses  # return the majority leaf\n",
        "\n",
        "    # otherwise, split on the best attribute\n",
        "    best_attribute = min(split_candidates,\n",
        "        key=partial(partition_entropy_by, inputs))\n",
        "\n",
        "    partitions = partition_by(inputs, best_attribute)\n",
        "    new_candidates = [a for a in split_candidates\n",
        "                      if a != best_attribute]\n",
        "\n",
        "    # recursively build the subtrees\n",
        "    subtrees = { attribute : build_tree_id3(subset, new_candidates)\n",
        "                 for attribute, subset in partitions.items() }\n",
        "\n",
        "    subtrees[None] = num_trues > num_falses # default case\n",
        "\n",
        "    return (best_attribute, subtrees)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e-iNrHAiKlui",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forest_classify(trees, input):\n",
        "    votes = [classify(tree, input) for tree in trees]\n",
        "    vote_counts = Counter(votes)\n",
        "    return vote_counts.most_common(1)[0][0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vFToZHGFKoN2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tree = build_tree_id3(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9u9dSdlLKzdm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e41fdb3d-46b7-4ec3-904c-19bc636c6830"
      },
      "cell_type": "code",
      "source": [
        "classify(tree, { \"level\" : \"Junior\",\n",
        "                \"lang\" : \"Java\",\n",
        "                \"tweets\" : \"yes\",\n",
        "                \"phd\" : \"no\"} ) \n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "wLTREXfqLUwy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b92cf660-ee0c-4f87-d4bd-737c8714ec47"
      },
      "cell_type": "code",
      "source": [
        "classify(tree, { \"level\" : \"Junior\",\n",
        "                \"lang\" : \"Java\",\n",
        "                \"tweets\" : \"yes\",\n",
        "                \"phd\" : \"yes\"} )"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "4ddgvbr1LY2S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2613220-045c-4f19-ecd3-a4848b61b875"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "classify(tree, { \"level\" : \"Senior\" } ) # False"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "9vPFlzu_LbAT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "159a73f0-717d-4ec9-df0f-2e5ca9c9284f"
      },
      "cell_type": "code",
      "source": [
        "classify(tree, { \"level\" : \"Intern\" } ) # True"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "AQ12E4M7Ld5i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}