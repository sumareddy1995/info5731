{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import sys, re\n",
    "# sys.argv is the list of command-line arguments\n",
    "# sys.argv[0] is the name of the program itself\n",
    "# sys.argv[1] will be the regex specified at the command line\n",
    "regex = sys.argv[1]\n",
    "# for every line passed into the script\n",
    "for line in sys.stdin:\n",
    "    # if it matches the regex, write it to stdout\n",
    "    if re.search(regex, line):       \n",
    "        sys.stdout.write(line)\n",
    "count = 0\n",
    "for line in sys.stdin:   \n",
    "    count += 1\n",
    "# print goes to sys.stdout\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deshi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from collections import Counter\n",
    "# pass in number of words as first argument\n",
    "try:\n",
    "    num_words = int(sys.argv[1])\n",
    "except:\n",
    "    print \n",
    "    sys.exit(1) # non-zero exit code indicates error\n",
    "counter = Counter(word.lower() # lowercase words\n",
    "            for line in sys.stdin #\n",
    "            for word in line.strip().split() # split on spaces\n",
    "            if word) # skip empty 'words'\n",
    "for word, count in counter.most_common(num_words):\n",
    "    sys.stdout.write(str(count))\n",
    "    sys.stdout.write(\"\\t\")\n",
    "    sys.stdout.write(word)\n",
    "    sys.stdout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7d5badb534cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstarts_with_hash\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'input.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# look at each line in the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"^#\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# use a regex to see if it starts with '#'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mstarts_with_hash\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input.txt'"
     ]
    }
   ],
   "source": [
    "starts_with_hash = 0\n",
    "with open('input.txt','r') as f:\n",
    "    for line in file: # look at each line in the file\n",
    "        if re.match(\"^#\",line): # use a regex to see if it starts with '#'\n",
    "            starts_with_hash += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'email_addresses.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-268d88b85d89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_domain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memail_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0memail_address\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"@\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'email_addresses.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     domain_counts = Counter(get_domain(line.strip())\n\u001b[0;32m      5\u001b[0m                             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'email_addresses.txt'"
     ]
    }
   ],
   "source": [
    "def get_domain(email_address):\n",
    "    return email_address.lower().split(\"@\")[-1]\n",
    "with open('email_addresses.txt', 'r') as f:\n",
    "    domain_counts = Counter(get_domain(line.strip())\n",
    "                            for line in f\n",
    "                            if \"@\" in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tab_delimited_stock_prices.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f4b8e89b8a93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tab_delimited_stock_prices.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tab_delimited_stock_prices.txt'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('tab_delimited_stock_prices.txt', 'rb') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        date = row[0]\n",
    "        symbol = row[1]\n",
    "        closing_price = float(row[2])\n",
    "        process(date, symbol, closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'colon_delimited_stock_prices.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-bc549edbc416>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'colon_delimited_stock_prices.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m':'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'colon_delimited_stock_prices.txt'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('colon_delimited_stock_prices.txt', 'rb') as f:\n",
    "    reader = csv.DictReader(f, delimiter=':')\n",
    "    for row in reader:\n",
    "        date = row[\"date\"]\n",
    "        symbol = row[\"symbol\"]\n",
    "        closing_price = float(row[\"closing_price\"])\n",
    "        process(date, symbol, closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-180a5096a8b9>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-180a5096a8b9>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    <html>\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<html>\n",
    " <head>\n",
    " <title>A web page</title>\n",
    " </head>\n",
    " <body>\n",
    " <p id=\"author\">Joel Grus</p>\n",
    " <p id=\"subject\">Data Science</p>\n",
    " </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "html = requests.get(\"http://www.google.com\").text\n",
    "soup = BeautifulSoup(html, 'html5lib')\n",
    "first_paragraph = soup.find('p') # or just soup.p\n",
    "first_paragraph\n",
    "all_paragraphs = soup.find_all('p') # or just soup('p')\n",
    "paragraphs_with_ids = [p for p in soup('p') if p.get('id')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paragraphs = soup.find_all('p') # or just soup('p')\n",
    "paragraphs_with_ids = [p for p in soup('p') if p.get('id')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_paragraphs = soup('p', {'class' : 'important'})\n",
    "important_paragraphs2 = soup('p', 'important')\n",
    "important_paragraphs3 = [p for p in soup('p')\n",
    "if 'important' in p.get('class', [])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spans_inside_divs = [span\n",
    "for div in soup('div') # for each <div> on the page\n",
    "for span in div('span')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://shop.oreilly.com/product/0636920050728.do\"\n",
    "soup = BeautifulSoup(requests.get(url).text, 'html5lib')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-22-9bc7b1bc3001>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-22-9bc7b1bc3001>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    <td class=\"thumbtext\">\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<td class=\"thumbtext\">\n",
    "<div class=\"thumbcontainer\">\n",
    "<div class=\"thumbdiv\">\n",
    "<a href=\"/product/9781118903407.do\">\n",
    "<img src=\"...\"/>\n",
    "</a>\n",
    "</div>\n",
    "</div>\n",
    "<div class=\"widthchange\">\n",
    "<div class=\"thumbheader\">\n",
    "<a href=\"/product/9781118903407.do\">Getting a Big Data Job For Dummies</a>\n",
    "</div>\n",
    "<div class=\"AuthorName\">By Jason Williamson</div>\n",
    "<span class=\"directorydate\"> December 2014 </span>\n",
    "<div style=\"clear:both;\">\n",
    "<div id=\"146350\">\n",
    "<span class=\"pricelabel\">\n",
    "Ebook:\n",
    "<span class=\"price\">&nbsp;$29.99</span>\n",
    "</span>\n",
    "</div>\n",
    "</div>\n",
    "</div>\n",
    "</td>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "tds = soup('td')\n",
    "print(len(tds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def is_video(td):\n",
    "    \"\"\"it's a video if it has exactly one pricelabel, and if\n",
    "    the stripped text inside that pricelabel starts with 'Video'\"\"\"\n",
    "    pricelabels = td('span', 'pricelabel')\n",
    "    return (len(pricelabels) == 1 and pricelabels[0].text.strip().startswith(\"Video\"))\n",
    "print(len([td for td in tds if not is_video(td)]))\n",
    "# 21 for me, might be different for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Data Science Book', 'author': 'Joel Grus', 'publicationYear': 2014, 'topics': ['data', 'science', 'data science']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "serialized = \"\"\"{ \"title\" : \"Data Science Book\",\n",
    "\"author\" : \"Joel Grus\",\n",
    "\"publicationYear\" : 2014,\n",
    "\"topics\" : [ \"data\", \"science\", \"data science\"] }\"\"\"\n",
    "# parse the JSON to create a Python dict\n",
    "deserialized = json.loads(serialized)\n",
    "if \"data science\" in deserialized[\"topics\"]:\n",
    "    print(deserialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Table : \n",
    "\n",
    "    def __init__(self, columns): \n",
    "        self.columns = columns \n",
    "        self.rows = []\n",
    "        \n",
    "    def __repr__(self): \n",
    "        \"\"\"pretty representation of the table: columns then rows\"\"\" \n",
    "        return str(self.columns) + \" \\n \" + \" \\n \".join(map(str, self.rows))\n",
    "\n",
    "    def insert(self, row_values): \n",
    "        if len(row_values) != len(self.columns): \n",
    "            raise TypeError (\"wrong number of elements\") \n",
    "        row_dict = dict(zip(self.columns, row_values)) \n",
    "        self.rows.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'name', 'num_friends'] \n",
      " {'user_id': 0, 'name': 'Hero', 'num_friends': 0} \n",
      " {'user_id': 1, 'name': 'Dunn', 'num_friends': 2} \n",
      " {'user_id': 2, 'name': 'Sue', 'num_friends': 3} \n",
      " {'user_id': 3, 'name': 'Chi', 'num_friends': 3} \n",
      " {'user_id': 4, 'name': 'Thor', 'num_friends': 3} \n",
      " {'user_id': 5, 'name': 'Clive', 'num_friends': 2} \n",
      " {'user_id': 6, 'name': 'Hicks', 'num_friends': 3} \n",
      " {'user_id': 7, 'name': 'Devin', 'num_friends': 2} \n",
      " {'user_id': 8, 'name': 'Kate', 'num_friends': 2} \n",
      " {'user_id': 9, 'name': 'Klein', 'num_friends': 3} \n",
      " {'user_id': 10, 'name': 'Jen', 'num_friends': 1}\n"
     ]
    }
   ],
   "source": [
    "users = Table ([\"user_id\", \"name\", \"num_friends\"]) \n",
    "users.insert([0, \"Hero\", 0]) \n",
    "users.insert([1, \"Dunn\", 2]) \n",
    "users.insert([2, \"Sue\", 3]) \n",
    "users.insert([3, \"Chi\", 3]) \n",
    "users.insert([4, \"Thor\", 3]) \n",
    "users.insert([5, \"Clive\", 2]) \n",
    "users.insert([6, \"Hicks\", 3]) \n",
    "users.insert([7, \"Devin\", 2]) \n",
    "users.insert([8, \"Kate\", 2]) \n",
    "users.insert([9, \"Klein\", 3]) \n",
    "users.insert([10, \"Jen\", 1])\n",
    "\n",
    "print(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'td' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-7d4acfd12bdb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"thumbheader\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'td' is not defined"
     ]
    }
   ],
   "source": [
    "title = td.find(\"div\", \"thumbheader\").a.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'td' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-bbe4b66d1936>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mauthor_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AuthorName'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mauthors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"^By \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauthor_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'td' is not defined"
     ]
    }
   ],
   "source": [
    "author_name=td.find('div', 'AuthorName').text\n",
    "authors=[x.strip() for x in re.sub(\"^By \", \"\", author_name).split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'td' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-fafb3719540e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0misbn_link\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"thumbheader\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"href\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0misbn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mremathc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/product/(.*)\\.do\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0misbn_link\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'td' is not defined"
     ]
    }
   ],
   "source": [
    "isbn_link=td.find('div',\"thumbheader\").a.get(\"href\")\n",
    "\n",
    "isbn=remathc(\"/product/(.*)\\.do\",isbn_link).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'td' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-cc8ea8412393>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"span\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"directorydate\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'td' is not defined"
     ]
    }
   ],
   "source": [
    "date=td.find(\"span\", \"directorydate\").text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_info(td):\n",
    "    \"\"\"given a BeautifulSoup <td> Tag representing a book, extract the book's details and return a dict\"\"\"\n",
    "    \n",
    "    title=td.find(\"div\", \"thumbheader\").a.text\n",
    "    by_authir=td.find('div', 'AuthorName').text\n",
    "    authors=[x.strip() for x in re.sub(\"^By \", \"\", by_author).split(\",\")]\n",
    "    isbn_link=td,find(\"div\", \"thumbheader\").a.get(\"href\")\n",
    "    isbn=re.match(\"/product/(.*)\\.do\", isbn_links).groups()[0]\n",
    "    date=td.find(\"span\", \"directorydate\").text.strip()\n",
    "    \n",
    "    return {\n",
    "        \"title\" : title,\n",
    "        \"authors\" : authors,\n",
    "        \"isbn\" : isbn, \n",
    "        \"date\" : date\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url=\"https://shop.oreilly.com/category/browse-subjects/data.do?sortby=publicationsDate&page=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "books=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PAGES=31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "souping page 1 , 0 found so far\n",
      "souping page 2 , 0 found so far\n",
      "souping page 3 , 0 found so far\n",
      "souping page 4 , 0 found so far\n",
      "souping page 5 , 0 found so far\n",
      "souping page 6 , 0 found so far\n",
      "souping page 7 , 0 found so far\n",
      "souping page 8 , 0 found so far\n",
      "souping page 9 , 0 found so far\n",
      "souping page 10 , 0 found so far\n",
      "souping page 11 , 0 found so far\n",
      "souping page 12 , 0 found so far\n",
      "souping page 13 , 0 found so far\n",
      "souping page 14 , 0 found so far\n",
      "souping page 15 , 0 found so far\n",
      "souping page 16 , 0 found so far\n",
      "souping page 17 , 0 found so far\n",
      "souping page 18 , 0 found so far\n",
      "souping page 19 , 0 found so far\n",
      "souping page 20 , 0 found so far\n",
      "souping page 21 , 0 found so far\n"
     ]
    }
   ],
   "source": [
    "for page_num in range(1, NUM_PAGES+ 1):\n",
    "    print (\"souping page\", page_num, \",\", len(books), \"found so far\")\n",
    "    url= base_url+str(page_num)\n",
    "    soup=BeautifulSoup(requests.get(url).text, 'html5lib')\n",
    "    \n",
    "    for td in soup('td', 'thunbtext'):\n",
    "        if not is_video(td):\n",
    "            books.append(book_info(td))\n",
    "    sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year(book):\n",
    "    \"\"\"book[\"date\"] looks like 'November 2014' so we need to split on the space and then take the second piece\"\"\"\n",
    "    return int(book[\"date\"].split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_counts=Counter(get_year(book) for book in books\n",
    "                   if get_year(book)<=2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years=sorted(year_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_counts=[year_counts[year]for year in years]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(years, book_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel(\"# of data books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f89705fd448d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# 2014 is the last complete year of data (when I ran this)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m year_counts = Counter(get_year(book) for book in books\n\u001b[0m\u001b[0;32m      8\u001b[0m                     if get_year(book) <= 2014)\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Counter' is not defined"
     ]
    }
   ],
   "source": [
    "def get_year(book):\n",
    "    \"\"\"book[\"date\"] looks like 'November 2014' so we need to\n",
    "    split on the space and then take the second piece\"\"\"\n",
    "    return int(book[\"date\"].split()[1])\n",
    "\n",
    "# 2014 is the last complete year of data (when I ran this)\n",
    "year_counts = Counter(get_year(book) for book in books\n",
    "                    if get_year(book) <= 2014)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "years = sorted(year_counts)\n",
    "book_counts = [year_counts[year] for year in years]\n",
    "plt.plot(years, book_counts)\n",
    "plt.ylabel(\"# of data books\")\n",
    "plt.title(\"Data is Big!\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "endpoint = \"https://api.github.com/users/joelgrus/repos\"\n",
    "\n",
    "repos = json.loads(requests.get(endpoint).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dateutil in c:\\users\\deshi\\anaconda3\\lib\\site-packages (2.7.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from python-dateutil) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dateutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-e9af0741c643>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"created_at\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrepo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrepos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmonth_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mweekday_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweekday\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth_counts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweekday_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Counter' is not defined"
     ]
    }
   ],
   "source": [
    "from dateutil.parser import parse\n",
    "\n",
    "dates = [parse(repo[\"created_at\"]) for repo in repos]\n",
    "month_counts = Counter(date.month for date in dates)\n",
    "weekday_counts = Counter(date.weekday() for date in dates)\n",
    "print(dates, month_counts, weekday_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 168755903, 'node_id': 'MDEwOlJlcG9zaXRvcnkxNjg3NTU5MDM=', 'name': 'awesome-podcasts', 'full_name': 'joelgrus/awesome-podcasts', 'private': False, 'owner': {'login': 'joelgrus', 'id': 1308313, 'node_id': 'MDQ6VXNlcjEzMDgzMTM=', 'avatar_url': 'https://avatars1.githubusercontent.com/u/1308313?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/joelgrus', 'html_url': 'https://github.com/joelgrus', 'followers_url': 'https://api.github.com/users/joelgrus/followers', 'following_url': 'https://api.github.com/users/joelgrus/following{/other_user}', 'gists_url': 'https://api.github.com/users/joelgrus/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/joelgrus/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/joelgrus/subscriptions', 'organizations_url': 'https://api.github.com/users/joelgrus/orgs', 'repos_url': 'https://api.github.com/users/joelgrus/repos', 'events_url': 'https://api.github.com/users/joelgrus/events{/privacy}', 'received_events_url': 'https://api.github.com/users/joelgrus/received_events', 'type': 'User', 'site_admin': False}, 'html_url': 'https://github.com/joelgrus/awesome-podcasts', 'description': 'Collection of awesome podcasts', 'fork': True, 'url': 'https://api.github.com/repos/joelgrus/awesome-podcasts', 'forks_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/forks', 'keys_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/keys{/key_id}', 'collaborators_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/collaborators{/collaborator}', 'teams_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/teams', 'hooks_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/hooks', 'issue_events_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/issues/events{/number}', 'events_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/events', 'assignees_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/assignees{/user}', 'branches_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/branches{/branch}', 'tags_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/tags', 'blobs_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/git/blobs{/sha}', 'git_tags_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/git/tags{/sha}', 'git_refs_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/git/refs{/sha}', 'trees_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/git/trees{/sha}', 'statuses_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/statuses/{sha}', 'languages_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/languages', 'stargazers_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/stargazers', 'contributors_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/contributors', 'subscribers_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/subscribers', 'subscription_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/subscription', 'commits_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/commits{/sha}', 'git_commits_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/git/commits{/sha}', 'comments_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/comments{/number}', 'issue_comment_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/issues/comments{/number}', 'contents_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/contents/{+path}', 'compare_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/compare/{base}...{head}', 'merges_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/merges', 'archive_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/{archive_format}{/ref}', 'downloads_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/downloads', 'issues_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/issues{/number}', 'pulls_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/pulls{/number}', 'milestones_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/milestones{/number}', 'notifications_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/notifications{?since,all,participating}', 'labels_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/labels{/name}', 'releases_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/releases{/id}', 'deployments_url': 'https://api.github.com/repos/joelgrus/awesome-podcasts/deployments', 'created_at': '2019-02-01T20:25:46Z', 'updated_at': '2019-02-01T20:25:47Z', 'pushed_at': '2019-02-01T20:29:18Z', 'git_url': 'git://github.com/joelgrus/awesome-podcasts.git', 'ssh_url': 'git@github.com:joelgrus/awesome-podcasts.git', 'clone_url': 'https://github.com/joelgrus/awesome-podcasts.git', 'svn_url': 'https://github.com/joelgrus/awesome-podcasts', 'homepage': '', 'size': 399, 'stargazers_count': 0, 'watchers_count': 0, 'language': None, 'has_issues': False, 'has_projects': True, 'has_downloads': True, 'has_wiki': True, 'has_pages': False, 'forks_count': 0, 'mirror_url': None, 'archived': False, 'open_issues_count': 0, 'license': None, 'forks': 0, 'open_issues': 0, 'watchers': 0, 'default_branch': 'master'}, {'id': 162483325, 'node_id': 'MDEwOlJlcG9zaXRvcnkxNjI0ODMzMjU=', 'name': 'allennlp-demo', 'full_name': 'joelgrus/allennlp-demo', 'private': False, 'owner': {'login': 'joelgrus', 'id': 1308313, 'node_id': 'MDQ6VXNlcjEzMDgzMTM=', 'avatar_url': 'https://avatars1.githubusercontent.com/u/1308313?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/joelgrus', 'html_url': 'https://github.com/joelgrus', 'followers_url': 'https://api.github.com/users/joelgrus/followers', 'following_url': 'https://api.github.com/users/joelgrus/following{/other_user}', 'gists_url': 'https://api.github.com/users/joelgrus/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/joelgrus/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/joelgrus/subscriptions', 'organizations_url': 'https://api.github.com/users/joelgrus/orgs', 'repos_url': 'https://api.github.com/users/joelgrus/repos', 'events_url': 'https://api.github.com/users/joelgrus/events{/privacy}', 'received_events_url': 'https://api.github.com/users/joelgrus/received_events', 'type': 'User', 'site_admin': False}, 'html_url': 'https://github.com/joelgrus/allennlp-demo', 'description': 'code for demo.allennlp.org', 'fork': True, 'url': 'https://api.github.com/repos/joelgrus/allennlp-demo', 'forks_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/forks', 'keys_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/keys{/key_id}', 'collaborators_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/collaborators{/collaborator}', 'teams_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/teams', 'hooks_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/hooks', 'issue_events_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/issues/events{/number}', 'events_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/events', 'assignees_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/assignees{/user}', 'branches_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/branches{/branch}', 'tags_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/tags', 'blobs_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/git/blobs{/sha}', 'git_tags_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/git/tags{/sha}', 'git_refs_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/git/refs{/sha}', 'trees_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/git/trees{/sha}', 'statuses_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/statuses/{sha}', 'languages_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/languages', 'stargazers_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/stargazers', 'contributors_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/contributors', 'subscribers_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/subscribers', 'subscription_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/subscription', 'commits_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/commits{/sha}', 'git_commits_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/git/commits{/sha}', 'comments_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/comments{/number}', 'issue_comment_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/issues/comments{/number}', 'contents_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/contents/{+path}', 'compare_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/compare/{base}...{head}', 'merges_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/merges', 'archive_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/{archive_format}{/ref}', 'downloads_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/downloads', 'issues_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/issues{/number}', 'pulls_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/pulls{/number}', 'milestones_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/milestones{/number}', 'notifications_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/notifications{?since,all,participating}', 'labels_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/labels{/name}', 'releases_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/releases{/id}', 'deployments_url': 'https://api.github.com/repos/joelgrus/allennlp-demo/deployments', 'created_at': '2018-12-19T19:44:45Z', 'updated_at': '2019-01-21T18:32:38Z', 'pushed_at': '2019-01-21T18:32:36Z', 'git_url': 'git://github.com/joelgrus/allennlp-demo.git', 'ssh_url': 'git@github.com:joelgrus/allennlp-demo.git', 'clone_url': 'https://github.com/joelgrus/allennlp-demo.git', 'svn_url': 'https://github.com/joelgrus/allennlp-demo', 'homepage': None, 'size': 35100, 'stargazers_count': 0, 'watchers_count': 0, 'language': 'Python', 'has_issues': False, 'has_projects': True, 'has_downloads': True, 'has_wiki': True, 'has_pages': False, 'forks_count': 0, 'mirror_url': None, 'archived': False, 'open_issues_count': 0, 'license': {'key': 'apache-2.0', 'name': 'Apache License 2.0', 'spdx_id': 'Apache-2.0', 'url': 'https://api.github.com/licenses/apache-2.0', 'node_id': 'MDc6TGljZW5zZTI='}, 'forks': 0, 'open_issues': 0, 'watchers': 0, 'default_branch': 'master'}, {'id': 159886377, 'node_id': 'MDEwOlJlcG9zaXRvcnkxNTk4ODYzNzc=', 'name': 'advent2018', 'full_name': 'joelgrus/advent2018', 'private': False, 'owner': {'login': 'joelgrus', 'id': 1308313, 'node_id': 'MDQ6VXNlcjEzMDgzMTM=', 'avatar_url': 'https://avatars1.githubusercontent.com/u/1308313?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/joelgrus', 'html_url': 'https://github.com/joelgrus', 'followers_url': 'https://api.github.com/users/joelgrus/followers', 'following_url': 'https://api.github.com/users/joelgrus/following{/other_user}', 'gists_url': 'https://api.github.com/users/joelgrus/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/joelgrus/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/joelgrus/subscriptions', 'organizations_url': 'https://api.github.com/users/joelgrus/orgs', 'repos_url': 'https://api.github.com/users/joelgrus/repos', 'events_url': 'https://api.github.com/users/joelgrus/events{/privacy}', 'received_events_url': 'https://api.github.com/users/joelgrus/received_events', 'type': 'User', 'site_admin': False}, 'html_url': 'https://github.com/joelgrus/advent2018', 'description': 'solutions for advent of code 2018', 'fork': False, 'url': 'https://api.github.com/repos/joelgrus/advent2018', 'forks_url': 'https://api.github.com/repos/joelgrus/advent2018/forks', 'keys_url': 'https://api.github.com/repos/joelgrus/advent2018/keys{/key_id}', 'collaborators_url': 'https://api.github.com/repos/joelgrus/advent2018/collaborators{/collaborator}', 'teams_url': 'https://api.github.com/repos/joelgrus/advent2018/teams', 'hooks_url': 'https://api.github.com/repos/joelgrus/advent2018/hooks', 'issue_events_url': 'https://api.github.com/repos/joelgrus/advent2018/issues/events{/number}', 'events_url': 'https://api.github.com/repos/joelgrus/advent2018/events', 'assignees_url': 'https://api.github.com/repos/joelgrus/advent2018/assignees{/user}', 'branches_url': 'https://api.github.com/repos/joelgrus/advent2018/branches{/branch}', 'tags_url': 'https://api.github.com/repos/joelgrus/advent2018/tags', 'blobs_url': 'https://api.github.com/repos/joelgrus/advent2018/git/blobs{/sha}', 'git_tags_url': 'https://api.github.com/repos/joelgrus/advent2018/git/tags{/sha}', 'git_refs_url': 'https://api.github.com/repos/joelgrus/advent2018/git/refs{/sha}', 'trees_url': 'https://api.github.com/repos/joelgrus/advent2018/git/trees{/sha}', 'statuses_url': 'https://api.github.com/repos/joelgrus/advent2018/statuses/{sha}', 'languages_url': 'https://api.github.com/repos/joelgrus/advent2018/languages', 'stargazers_url': 'https://api.github.com/repos/joelgrus/advent2018/stargazers', 'contributors_url': 'https://api.github.com/repos/joelgrus/advent2018/contributors', 'subscribers_url': 'https://api.github.com/repos/joelgrus/advent2018/subscribers', 'subscription_url': 'https://api.github.com/repos/joelgrus/advent2018/subscription', 'commits_url': 'https://api.github.com/repos/joelgrus/advent2018/commits{/sha}', 'git_commits_url': 'https://api.github.com/repos/joelgrus/advent2018/git/commits{/sha}', 'comments_url': 'https://api.github.com/repos/joelgrus/advent2018/comments{/number}', 'issue_comment_url': 'https://api.github.com/repos/joelgrus/advent2018/issues/comments{/number}', 'contents_url': 'https://api.github.com/repos/joelgrus/advent2018/contents/{+path}', 'compare_url': 'https://api.github.com/repos/joelgrus/advent2018/compare/{base}...{head}', 'merges_url': 'https://api.github.com/repos/joelgrus/advent2018/merges', 'archive_url': 'https://api.github.com/repos/joelgrus/advent2018/{archive_format}{/ref}', 'downloads_url': 'https://api.github.com/repos/joelgrus/advent2018/downloads', 'issues_url': 'https://api.github.com/repos/joelgrus/advent2018/issues{/number}', 'pulls_url': 'https://api.github.com/repos/joelgrus/advent2018/pulls{/number}', 'milestones_url': 'https://api.github.com/repos/joelgrus/advent2018/milestones{/number}', 'notifications_url': 'https://api.github.com/repos/joelgrus/advent2018/notifications{?since,all,participating}', 'labels_url': 'https://api.github.com/repos/joelgrus/advent2018/labels{/name}', 'releases_url': 'https://api.github.com/repos/joelgrus/advent2018/releases{/id}', 'deployments_url': 'https://api.github.com/repos/joelgrus/advent2018/deployments', 'created_at': '2018-11-30T22:41:16Z', 'updated_at': '2019-01-06T21:06:41Z', 'pushed_at': '2018-12-19T06:04:24Z', 'git_url': 'git://github.com/joelgrus/advent2018.git', 'ssh_url': 'git@github.com:joelgrus/advent2018.git', 'clone_url': 'https://github.com/joelgrus/advent2018.git', 'svn_url': 'https://github.com/joelgrus/advent2018', 'homepage': None, 'size': 121, 'stargazers_count': 13, 'watchers_count': 13, 'language': 'Python', 'has_issues': True, 'has_projects': True, 'has_downloads': True, 'has_wiki': True, 'has_pages': False, 'forks_count': 1, 'mirror_url': None, 'archived': False, 'open_issues_count': 0, 'license': {'key': 'unlicense', 'name': 'The Unlicense', 'spdx_id': 'Unlicense', 'url': 'https://api.github.com/licenses/unlicense', 'node_id': 'MDc6TGljZW5zZTE1'}, 'forks': 1, 'open_issues': 0, 'watchers': 13, 'default_branch': 'master'}, {'id': 149900501, 'node_id': 'MDEwOlJlcG9zaXRvcnkxNDk5MDA1MDE=', 'name': 'data', 'full_name': 'joelgrus/data', 'private': False, 'owner': {'login': 'joelgrus', 'id': 1308313, 'node_id': 'MDQ6VXNlcjEzMDgzMTM=', 'avatar_url': 'https://avatars1.githubusercontent.com/u/1308313?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/joelgrus', 'html_url': 'https://github.com/joelgrus', 'followers_url': 'https://api.github.com/users/joelgrus/followers', 'following_url': 'https://api.github.com/users/joelgrus/following{/other_user}', 'gists_url': 'https://api.github.com/users/joelgrus/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/joelgrus/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/joelgrus/subscriptions', 'organizations_url': 'https://api.github.com/users/joelgrus/orgs', 'repos_url': 'https://api.github.com/users/joelgrus/repos', 'events_url': 'https://api.github.com/users/joelgrus/events{/privacy}', 'received_events_url': 'https://api.github.com/users/joelgrus/received_events', 'type': 'User', 'site_admin': False}, 'html_url': 'https://github.com/joelgrus/data', 'description': 'datasets for data science from scratch', 'fork': False, 'url': 'https://api.github.com/repos/joelgrus/data', 'forks_url': 'https://api.github.com/repos/joelgrus/data/forks', 'keys_url': 'https://api.github.com/repos/joelgrus/data/keys{/key_id}', 'collaborators_url': 'https://api.github.com/repos/joelgrus/data/collaborators{/collaborator}', 'teams_url': 'https://api.github.com/repos/joelgrus/data/teams', 'hooks_url': 'https://api.github.com/repos/joelgrus/data/hooks', 'issue_events_url': 'https://api.github.com/repos/joelgrus/data/issues/events{/number}', 'events_url': 'https://api.github.com/repos/joelgrus/data/events', 'assignees_url': 'https://api.github.com/repos/joelgrus/data/assignees{/user}', 'branches_url': 'https://api.github.com/repos/joelgrus/data/branches{/branch}', 'tags_url': 'https://api.github.com/repos/joelgrus/data/tags', 'blobs_url': 'https://api.github.com/repos/joelgrus/data/git/blobs{/sha}', 'git_tags_url': 'https://api.github.com/repos/joelgrus/data/git/tags{/sha}', 'git_refs_url': 'https://api.github.com/repos/joelgrus/data/git/refs{/sha}', 'trees_url': 'https://api.github.com/repos/joelgrus/data/git/trees{/sha}', 'statuses_url': 'https://api.github.com/repos/joelgrus/data/statuses/{sha}', 'languages_url': 'https://api.github.com/repos/joelgrus/data/languages', 'stargazers_url': 'https://api.github.com/repos/joelgrus/data/stargazers', 'contributors_url': 'https://api.github.com/repos/joelgrus/data/contributors', 'subscribers_url': 'https://api.github.com/repos/joelgrus/data/subscribers', 'subscription_url': 'https://api.github.com/repos/joelgrus/data/subscription', 'commits_url': 'https://api.github.com/repos/joelgrus/data/commits{/sha}', 'git_commits_url': 'https://api.github.com/repos/joelgrus/data/git/commits{/sha}', 'comments_url': 'https://api.github.com/repos/joelgrus/data/comments{/number}', 'issue_comment_url': 'https://api.github.com/repos/joelgrus/data/issues/comments{/number}', 'contents_url': 'https://api.github.com/repos/joelgrus/data/contents/{+path}', 'compare_url': 'https://api.github.com/repos/joelgrus/data/compare/{base}...{head}', 'merges_url': 'https://api.github.com/repos/joelgrus/data/merges', 'archive_url': 'https://api.github.com/repos/joelgrus/data/{archive_format}{/ref}', 'downloads_url': 'https://api.github.com/repos/joelgrus/data/downloads', 'issues_url': 'https://api.github.com/repos/joelgrus/data/issues{/number}', 'pulls_url': 'https://api.github.com/repos/joelgrus/data/pulls{/number}', 'milestones_url': 'https://api.github.com/repos/joelgrus/data/milestones{/number}', 'notifications_url': 'https://api.github.com/repos/joelgrus/data/notifications{?since,all,participating}', 'labels_url': 'https://api.github.com/repos/joelgrus/data/labels{/name}', 'releases_url': 'https://api.github.com/repos/joelgrus/data/releases{/id}', 'deployments_url': 'https://api.github.com/repos/joelgrus/data/deployments', 'created_at': '2018-09-22T17:30:59Z', 'updated_at': '2018-10-01T18:36:18Z', 'pushed_at': '2018-09-22T17:32:03Z', 'git_url': 'git://github.com/joelgrus/data.git', 'ssh_url': 'git@github.com:joelgrus/data.git', 'clone_url': 'https://github.com/joelgrus/data.git', 'svn_url': 'https://github.com/joelgrus/data', 'homepage': None, 'size': 1, 'stargazers_count': 3, 'watchers_count': 3, 'language': 'HTML', 'has_issues': True, 'has_projects': True, 'has_downloads': True, 'has_wiki': True, 'has_pages': False, 'forks_count': 0, 'mirror_url': None, 'archived': False, 'open_issues_count': 0, 'license': None, 'forks': 0, 'open_issues': 0, 'watchers': 3, 'default_branch': 'master'}, {'id': 149889203, 'node_id': 'MDEwOlJlcG9zaXRvcnkxNDk4ODkyMDM=', 'name': 'CNTK', 'full_name': 'joelgrus/CNTK', 'private': False, 'owner': {'login': 'joelgrus', 'id': 1308313, 'node_id': 'MDQ6VXNlcjEzMDgzMTM=', 'avatar_url': 'https://avatars1.githubusercontent.com/u/1308313?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/joelgrus', 'html_url': 'https://github.com/joelgrus', 'followers_url': 'https://api.github.com/users/joelgrus/followers', 'following_url': 'https://api.github.com/users/joelgrus/following{/other_user}', 'gists_url': 'https://api.github.com/users/joelgrus/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/joelgrus/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/joelgrus/subscriptions', 'organizations_url': 'https://api.github.com/users/joelgrus/orgs', 'repos_url': 'https://api.github.com/users/joelgrus/repos', 'events_url': 'https://api.github.com/users/joelgrus/events{/privacy}', 'received_events_url': 'https://api.github.com/users/joelgrus/received_events', 'type': 'User', 'site_admin': False}, 'html_url': 'https://github.com/joelgrus/CNTK', 'description': 'Microsoft Cognitive Toolkit (CNTK), an open source deep-learning toolkit', 'fork': True, 'url': 'https://api.github.com/repos/joelgrus/CNTK', 'forks_url': 'https://api.github.com/repos/joelgrus/CNTK/forks', 'keys_url': 'https://api.github.com/repos/joelgrus/CNTK/keys{/key_id}', 'collaborators_url': 'https://api.github.com/repos/joelgrus/CNTK/collaborators{/collaborator}', 'teams_url': 'https://api.github.com/repos/joelgrus/CNTK/teams', 'hooks_url': 'https://api.github.com/repos/joelgrus/CNTK/hooks', 'issue_events_url': 'https://api.github.com/repos/joelgrus/CNTK/issues/events{/number}', 'events_url': 'https://api.github.com/repos/joelgrus/CNTK/events', 'assignees_url': 'https://api.github.com/repos/joelgrus/CNTK/assignees{/user}', 'branches_url': 'https://api.github.com/repos/joelgrus/CNTK/branches{/branch}', 'tags_url': 'https://api.github.com/repos/joelgrus/CNTK/tags', 'blobs_url': 'https://api.github.com/repos/joelgrus/CNTK/git/blobs{/sha}', 'git_tags_url': 'https://api.github.com/repos/joelgrus/CNTK/git/tags{/sha}', 'git_refs_url': 'https://api.github.com/repos/joelgrus/CNTK/git/refs{/sha}', 'trees_url': 'https://api.github.com/repos/joelgrus/CNTK/git/trees{/sha}', 'statuses_url': 'https://api.github.com/repos/joelgrus/CNTK/statuses/{sha}', 'languages_url': 'https://api.github.com/repos/joelgrus/CNTK/languages', 'stargazers_url': 'https://api.github.com/repos/joelgrus/CNTK/stargazers', 'contributors_url': 'https://api.github.com/repos/joelgrus/CNTK/contributors', 'subscribers_url': 'https://api.github.com/repos/joelgrus/CNTK/subscribers', 'subscription_url': 'https://api.github.com/repos/joelgrus/CNTK/subscription', 'commits_url': 'https://api.github.com/repos/joelgrus/CNTK/commits{/sha}', 'git_commits_url': 'https://api.github.com/repos/joelgrus/CNTK/git/commits{/sha}', 'comments_url': 'https://api.github.com/repos/joelgrus/CNTK/comments{/number}', 'issue_comment_url': 'https://api.github.com/repos/joelgrus/CNTK/issues/comments{/number}', 'contents_url': 'https://api.github.com/repos/joelgrus/CNTK/contents/{+path}', 'compare_url': 'https://api.github.com/repos/joelgrus/CNTK/compare/{base}...{head}', 'merges_url': 'https://api.github.com/repos/joelgrus/CNTK/merges', 'archive_url': 'https://api.github.com/repos/joelgrus/CNTK/{archive_format}{/ref}', 'downloads_url': 'https://api.github.com/repos/joelgrus/CNTK/downloads', 'issues_url': 'https://api.github.com/repos/joelgrus/CNTK/issues{/number}', 'pulls_url': 'https://api.github.com/repos/joelgrus/CNTK/pulls{/number}', 'milestones_url': 'https://api.github.com/repos/joelgrus/CNTK/milestones{/number}', 'notifications_url': 'https://api.github.com/repos/joelgrus/CNTK/notifications{?since,all,participating}', 'labels_url': 'https://api.github.com/repos/joelgrus/CNTK/labels{/name}', 'releases_url': 'https://api.github.com/repos/joelgrus/CNTK/releases{/id}', 'deployments_url': 'https://api.github.com/repos/joelgrus/CNTK/deployments', 'created_at': '2018-09-22T15:23:50Z', 'updated_at': '2018-09-22T15:24:37Z', 'pushed_at': '2018-09-22T15:24:31Z', 'git_url': 'git://github.com/joelgrus/CNTK.git', 'ssh_url': 'git@github.com:joelgrus/CNTK.git', 'clone_url': 'https://github.com/joelgrus/CNTK.git', 'svn_url': 'https://github.com/joelgrus/CNTK', 'homepage': 'https://docs.microsoft.com/cognitive-toolkit/', 'size': 706685, 'stargazers_count': 0, 'watchers_count': 0, 'language': 'C++', 'has_issues': False, 'has_projects': True, 'has_downloads': True, 'has_wiki': True, 'has_pages': False, 'forks_count': 0, 'mirror_url': None, 'archived': False, 'open_issues_count': 0, 'license': {'key': 'other', 'name': 'Other', 'spdx_id': 'NOASSERTION', 'url': None, 'node_id': 'MDc6TGljZW5zZTA='}, 'forks': 0, 'open_issues': 0, 'watchers': 0, 'default_branch': 'master'}]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[None, 'Python', 'Python', 'HTML', 'C++']\n"
     ]
    }
   ],
   "source": [
    "last_5_repositories = sorted(repos,\n",
    "                            key=lambda r: r[\"created_at\"],\n",
    "                            reverse=True)[:5]\n",
    "last_5_languages = [repo[\"language\"]\n",
    "                    for repo in last_5_repositories]\n",
    "print(last_5_repositories)\n",
    "print(last_5_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting twython\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/2b/c0883f05b03a8e87787d56395d6c89515fe7e0bf80abd3778b6bb3a6873f/twython-3.7.0.tar.gz\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from twython) (2.21.0)\n",
      "Collecting requests_oauthlib>=0.4.0 (from twython)\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/e2/9fd03d55ffb70fe51f587f20bcf407a6927eb121de86928b34d162f0b1ac/requests_oauthlib-1.2.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from requests>=2.1.0->twython) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from requests>=2.1.0->twython) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from requests>=2.1.0->twython) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from requests>=2.1.0->twython) (2018.11.29)\n",
      "Collecting oauthlib>=3.0.0 (from requests_oauthlib>=0.4.0->twython)\n",
      "  Downloading https://files.pythonhosted.org/packages/16/95/699466b05b72b94a41f662dc9edf87fda4289e3602ecd42d27fcaddf7b56/oauthlib-3.0.1-py2.py3-none-any.whl (142kB)\n",
      "Building wheels for collected packages: twython\n",
      "  Running setup.py bdist_wheel for twython: started\n",
      "  Running setup.py bdist_wheel for twython: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\deshi\\AppData\\Local\\pip\\Cache\\wheels\\c2\\b0\\a3\\5c4b4b87b8c9e4d99f1494a0b471f0134a74e5fb33d426d009\n",
      "Successfully built twython\n",
      "Installing collected packages: oauthlib, requests-oauthlib, twython\n",
      "Successfully installed oauthlib-3.0.1 requests-oauthlib-1.2.0 twython-3.7.0\n",
      "b'ESIPfed' : b'Six-newly funded Lab projects and how to streamline your data science workflows with OCCUR! - https://t.co/M8kpeObp6u'\n",
      "b'WiDSTO' : b\"If you thought last year's conference was something, just wait and see what we have planned for 2019! TICKETS ARE O\\xe2\\x80\\xa6 https://t.co/8j14RscYGN\"\n",
      "b'Vircourses' : b'R Programming A-Z\\xe2\\x84\\xa2: R For Data Science With Real Exercises!\\nLearn Programming In R And R Studio. Data Analytics, Da\\xe2\\x80\\xa6 https://t.co/TG3KL54Vgr'\n",
      "b'uddenfeldt' : b'RT @mesosphere: Is the Feature Store the missing API between Data Engineering and Data Science? Join us and @jim_dowling, CEO of @logicalcl\\xe2\\x80\\xa6'\n",
      "b'prestamospain' : b'Gemproject recomendado Data Science est\\xc3\\xa1 cambiando la vida de 7500M en el planeta. Apr\\xc3\\xa9nde https://t.co/vJsYjrhJhI https://t.co/vAMsagnopd'\n",
      "b'knime' : b'Upcoming webinar: Sharing &amp; Deploying #DataScience with #KNIME #Server on Feb 13. Join us to learn about newly rele\\xe2\\x80\\xa6 https://t.co/QqX7H1EJxw'\n",
      "b'velocimetrics' : b'Major #DataScience and #BigData Predictions To Watch In 2019 @SmartDataCo \\n\\nhttps://t.co/1xWpDDUN7b'\n",
      "b'roblwilson' : b'RT @YungWu: What a pleasure hosting First Minister of Scotland @NicolaSturgeon at @MaRSDD ! A wide-ranging &amp; thoughtful discussion about sh\\xe2\\x80\\xa6'\n",
      "b'ETS_Talent' : b'Ya pod\\xc3\\xa9is consultar las diapositivas de nuestras charlas:\\n\\n\\xe2\\x9c\\xb4\\xef\\xb8\\x8f\"Aplicaciones pr\\xc3\\xa1cticas del #DataScience que (probable\\xe2\\x80\\xa6 https://t.co/Rd4MVDFZMW'\n",
      "b'phana5577' : b'RT @salmon_0511: \\xe6\\x9d\\xa5\\xe5\\xb9\\xb4\\xe5\\xba\\xa6\\xe3\\x81\\x8b\\xe3\\x82\\x89\\xe6\\x9d\\xb1\\xe5\\x8c\\x97\\xe5\\xa4\\xa7\\xe5\\xad\\xa6\\xe3\\x81\\xa7\\xe3\\x80\\x8c\\xe6\\x9c\\xaa\\xe6\\x9d\\xa5\\xe5\\x9e\\x8b\\xe5\\x8c\\xbb\\xe7\\x99\\x82\\xe5\\x89\\xb5\\xe9\\x80\\xa0\\xe5\\x8d\\x93\\xe8\\xb6\\x8a\\xe5\\xa4\\xa7\\xe5\\xad\\xa6\\xe9\\x99\\xa2\\xe3\\x83\\x97\\xe3\\x83\\xad\\xe3\\x82\\xb0\\xe3\\x83\\xa9\\xe3\\x83\\xa0\\xe3\\x80\\x8d\\xe3\\x81\\x8c\\xe9\\x96\\x8b\\xe5\\x82\\xac\\n\\xe3\\x82\\xb3\\xe3\\x83\\xbc\\xe3\\x82\\xb9\\xe3\\x81\\xaf\\xe3\\x80\\x8cData Science\\xe3\\x83\\xbbTechnology\\xe3\\x83\\xbbSociety\\xe3\\x80\\x8d\\xe3\\x81\\xae3\\xe3\\x81\\xa4\\xe3\\x81\\x8b\\xe3\\x82\\x89\\xe3\\x81\\xaa\\xe3\\x82\\x8a\\xe3\\x80\\x81\\xe7\\x90\\x86\\xe5\\xb7\\xa5\\xe7\\xb3\\xbb\\xe3\\x80\\x81\\xe6\\x96\\x87\\xe7\\xb3\\xbb\\xe5\\xad\\xa6\\xe9\\x83\\xa8\\xe3\\x81\\xaa\\xe3\\x81\\xa9\\xe3\\x80\\x81\\xe7\\x95\\xb0\\xe3\\x81\\xaa\\xe3\\x82\\x8b\\xe3\\x83\\x90\\xe3\\x83\\x83\\xe3\\x82\\xaf\\xe3\\x82\\xb0\\xe3\\x83\\xa9\\xe3\\x82\\xa6\\xe3\\x83\\xb3\\xe3\\x83\\x89\\xe3\\x82\\x92\\xe6\\x8c\\x81\\xe3\\x81\\xa4\\xe5\\xad\\xa6\\xe7\\x94\\x9f\\xe3\\x81\\x8c\\xe5\\x8b\\x9f\\xe9\\x9b\\x86\\xe3\\x81\\x95\\xe3\\x82\\x8c\\xe3\\x81\\xa6\\xe3\\x81\\x84\\xe3\\x81\\xbe\\xe3\\x81\\x99\\n\\n\\xe7\\xb7\\x8f\\xe5\\x90\\x88\\xe5\\xa4\\xa7\\xe5\\xad\\xa6\\xe3\\x81\\xae\\xe6\\x9c\\x80\\xe2\\x80\\xa6'\n",
      "b'Nyanru_Money21' : b'RT @salmon_0511: \\xe6\\x9d\\xa5\\xe5\\xb9\\xb4\\xe5\\xba\\xa6\\xe3\\x81\\x8b\\xe3\\x82\\x89\\xe6\\x9d\\xb1\\xe5\\x8c\\x97\\xe5\\xa4\\xa7\\xe5\\xad\\xa6\\xe3\\x81\\xa7\\xe3\\x80\\x8c\\xe6\\x9c\\xaa\\xe6\\x9d\\xa5\\xe5\\x9e\\x8b\\xe5\\x8c\\xbb\\xe7\\x99\\x82\\xe5\\x89\\xb5\\xe9\\x80\\xa0\\xe5\\x8d\\x93\\xe8\\xb6\\x8a\\xe5\\xa4\\xa7\\xe5\\xad\\xa6\\xe9\\x99\\xa2\\xe3\\x83\\x97\\xe3\\x83\\xad\\xe3\\x82\\xb0\\xe3\\x83\\xa9\\xe3\\x83\\xa0\\xe3\\x80\\x8d\\xe3\\x81\\x8c\\xe9\\x96\\x8b\\xe5\\x82\\xac\\n\\xe3\\x82\\xb3\\xe3\\x83\\xbc\\xe3\\x82\\xb9\\xe3\\x81\\xaf\\xe3\\x80\\x8cData Science\\xe3\\x83\\xbbTechnology\\xe3\\x83\\xbbSociety\\xe3\\x80\\x8d\\xe3\\x81\\xae3\\xe3\\x81\\xa4\\xe3\\x81\\x8b\\xe3\\x82\\x89\\xe3\\x81\\xaa\\xe3\\x82\\x8a\\xe3\\x80\\x81\\xe7\\x90\\x86\\xe5\\xb7\\xa5\\xe7\\xb3\\xbb\\xe3\\x80\\x81\\xe6\\x96\\x87\\xe7\\xb3\\xbb\\xe5\\xad\\xa6\\xe9\\x83\\xa8\\xe3\\x81\\xaa\\xe3\\x81\\xa9\\xe3\\x80\\x81\\xe7\\x95\\xb0\\xe3\\x81\\xaa\\xe3\\x82\\x8b\\xe3\\x83\\x90\\xe3\\x83\\x83\\xe3\\x82\\xaf\\xe3\\x82\\xb0\\xe3\\x83\\xa9\\xe3\\x82\\xa6\\xe3\\x83\\xb3\\xe3\\x83\\x89\\xe3\\x82\\x92\\xe6\\x8c\\x81\\xe3\\x81\\xa4\\xe5\\xad\\xa6\\xe7\\x94\\x9f\\xe3\\x81\\x8c\\xe5\\x8b\\x9f\\xe9\\x9b\\x86\\xe3\\x81\\x95\\xe3\\x82\\x8c\\xe3\\x81\\xa6\\xe3\\x81\\x84\\xe3\\x81\\xbe\\xe3\\x81\\x99\\n\\n\\xe7\\xb7\\x8f\\xe5\\x90\\x88\\xe5\\xa4\\xa7\\xe5\\xad\\xa6\\xe3\\x81\\xae\\xe6\\x9c\\x80\\xe2\\x80\\xa6'\n",
      "b'OrientaMfalla' : b\"RT @CodimgVA: Master's degree in Simulation &amp; Data Science marks the advance of data-driven learning. As a university in Cyprus launches a\\xe2\\x80\\xa6\"\n",
      "b'Mississippi_HR' : b'Data Analyst: Responsibilities Data Analyst will be responsible for using a variety of tools and methods to extract\\xe2\\x80\\xa6 https://t.co/4qHKoDJ3v1'\n",
      "b'Rhode_Island_HR' : b'Flood Data Scientist: Coastal/Storm Surge: Flood Data Scientist: Coastal/Storm Surge Menlo Park Data Science Full T\\xe2\\x80\\xa6 https://t.co/ioH4erlaOh'\n",
      "b'ThomasNiebler' : b'RT @ghdatascience: @DeepIndaba @BenjaminRosman @siminyu_kat We are glad to be part of this! Apply to our maiden Ghana Data Science Summit 2\\xe2\\x80\\xa6'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install twython\n",
    "from twython import Twython\n",
    "\n",
    "twitter = Twython('nUZFwLeW7oLoF8exHRbLZZfio', 'RmRkTiINVfzrlv0wcYakV8AtJTN3SaGrm4bSNQb675lVXhBXBQ')\n",
    "\n",
    "# search for tweets containing the phrase \"data science\"\n",
    "for status in twitter.search(q='\"data science\"')[\"statuses\"]:\n",
    "    user = status[\"user\"][\"screen_name\"].encode('utf-8')\n",
    "    text = status[\"text\"].encode('utf-8')\n",
    "    print(user, \":\", text)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import TwythonStreamer\n",
    "\n",
    "# appending data to a global variable is pretty poor form\n",
    "# but it makes the example much simpler\n",
    "tweets = []\n",
    "\n",
    "class MyStreamer(TwythonStreamer):\n",
    "    \"\"\"our own subclass of TwythonStreamer that specifies\n",
    "    how to interact with the stream\"\"\"\n",
    "\n",
    "    def on_success(self, data):\n",
    "        \"\"\"what do we do when twitter sends us data?\n",
    "        here data will be a Python dict representing a tweet\"\"\"\n",
    "\n",
    "        # only want to collect English-language tweets\n",
    "        if data['lang'] == 'en':\n",
    "            tweets.append(data)\n",
    "            print(\"received tweet #\", len(tweets))\n",
    "\n",
    "        # stop when we've collected enough\n",
    "        if len(tweets) >= 10:\n",
    "            self.disconnect()\n",
    "\n",
    "def on_error(self, status_code, data):\n",
    "    print(status_code, data)\n",
    "    self.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MyStreamer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-5180cca5bdcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m stream = MyStreamer('nUZFwLeW7oLoF8exHRbLZZfio', 'RmRkTiINVfzrlv0wcYakV8AtJTN3SaGrm4bSNQb675lVXhBXBQ',\n\u001b[0m\u001b[0;32m      2\u001b[0m                     '1922183460-0P2azuFwg7DQZaNQIRYNctCUvk1NAyzK9BkF5bU', 'j5nTzIMlw3X9AKVD2crHlHqtpapPJXzhkrMW0w4rPeqJL')\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# starts consuming public statuses that contain the keyword 'data'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatuses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MyStreamer' is not defined"
     ]
    }
   ],
   "source": [
    "stream = MyStreamer('nUZFwLeW7oLoF8exHRbLZZfio', 'RmRkTiINVfzrlv0wcYakV8AtJTN3SaGrm4bSNQb675lVXhBXBQ',\n",
    "                    '1922183460-0P2azuFwg7DQZaNQIRYNctCUvk1NAyzK9BkF5bU', 'j5nTzIMlw3X9AKVD2crHlHqtpapPJXzhkrMW0w4rPeqJL')\n",
    "# starts consuming public statuses that contain the keyword 'data'\n",
    "stream.statuses.filter(track='data')\n",
    "\n",
    "\n",
    "# if instead we wanted to start consuming a sample of *all* public statuses\n",
    "# stream.statuses.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a49381160136>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m top_hashtags = Counter(hashtag['text'].lower()\n\u001b[0m\u001b[0;32m      2\u001b[0m                         \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                         for hashtag in tweet[\"entities\"][\"hashtags\"])\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_hashtags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Counter' is not defined"
     ]
    }
   ],
   "source": [
    "top_hashtags = Counter(hashtag['text'].lower()\n",
    "                        for tweet in tweets\n",
    "                        for hashtag in tweet[\"entities\"][\"hashtags\"])\n",
    "\n",
    "print(top_hashtags.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [[0, \"Ron\", 0],\n",
    "[1, \"Josh\", 2],\n",
    "[2, \"Hank\", 3],\n",
    "[3, \"Chi-chi\", 3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classwork lesson 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests_html in c:\\users\\deshi\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from requests_html) (2.21.0)\n",
      "Requirement already satisfied: w3lib in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from requests_html) (1.20.0)\n",
      "Requirement already satisfied: parse in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from requests_html) (1.11.1)\n",
      "Requirement already satisfied: pyppeteer>=0.0.14 in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from requests_html) (0.0.25)\n",
      "Requirement already satisfied: fake-useragent in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from requests_html) (0.1.11)\n",
      "Requirement already satisfied: pyquery in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from requests_html) (1.4.0)\n",
      "Requirement already satisfied: bs4 in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from requests_html) (0.0.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from requests->requests_html) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from requests->requests_html) (2018.11.29)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from requests->requests_html) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from requests->requests_html) (1.24.1)\n",
      "Requirement already satisfied: six>=1.4.1 in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from w3lib->requests_html) (1.12.0)\n",
      "Requirement already satisfied: websockets in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests_html) (7.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests_html) (4.28.1)\n",
      "Requirement already satisfied: appdirs in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests_html) (1.4.3)\n",
      "Requirement already satisfied: pyee in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests_html) (5.0.0)\n",
      "Requirement already satisfied: lxml>=2.1 in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from pyquery->requests_html) (4.2.5)\n",
      "Requirement already satisfied: cssselect>0.7.9 in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from pyquery->requests_html) (1.0.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\deshi\\anaconda3\\lib\\site-packages (from bs4->requests_html) (4.6.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests_html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.cleveland.com/metro/index.ssf/2017/12/case_western_reserve_university_president_barbara_snyders_base_salary_and_bonus_pay_tops_among_private_colleges_in_ohio.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = HTMLSession().get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = r.html.find('#entryContent > ul:nth-child(7)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1= element[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Grant Cornwell, College of Wooster (left in 2015): $911,651\\nMarvin Krislov, Oberlin College (left in 2016): \\xa0$829,913\\nMark Roosevelt, Antioch College, (left in 2015): $507,672\\nLaurie Joyner, Wittenberg University (left in 2015): $463,504\\nRichard Giese, University of Mount Union (left in 2015): $453,800\\nSean Decatur,Kenyon College: $451,698\\nAdam Weinberg, Denison University: $435,322\\nDaniel Dibiasio, Ohio Northern University: $414,716\\nDenvy Bowman, Capital University (left in 2016): $388,570\\nAnne Steele, Muskingum University (left in 2016): $384,233\\nKathy Krendl, Otterbein University: \\xa0$378,035\\nRockwell Jones, Ohio Wesleyan University: $366,625\\nRobert Helmer, Baldwin Wallace University: $365,616\\nRobert Huntington, Heidelberg University: $300,005\\nLori Varlotta, Hiram College: $293,336\\nJoseph Bruno, Marietta College (left in 2016): $288,295\\nW. Richard Merriman Jr., University of Mount Union (started in June 2015): $221,761'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[', College of Wooster (',\n",
       " ', Oberlin College (',\n",
       " ', Antioch College, (',\n",
       " ', Wittenberg University (',\n",
       " ', University of Mount Union (',\n",
       " ',Kenyon College:',\n",
       " ', Denison University:',\n",
       " ', Ohio Northern University:',\n",
       " ', Capital University (',\n",
       " ', Muskingum University (',\n",
       " ', Otterbein University:',\n",
       " ', Ohio Wesleyan University:',\n",
       " ', Baldwin Wallace University:',\n",
       " ', Heidelberg University:',\n",
       " ', Hiram College:',\n",
       " ', Marietta College (',\n",
       " ', University of Mount Union (']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "college_names = re.findall(r\"\\,\\D+[\\,\\(:]\", list1)\n",
    "college_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['911,651', '829,913', '507,672', '463,504', '453,800', '451,698', '435,322', '414,716', '388,570', '384,233', '378,035', '366,625', '365,616', '300,005', '293,336', '288,295', '221,761']\n"
     ]
    }
   ],
   "source": [
    "amount1 = re.findall('\\d\\d\\d,\\d\\d\\d',list1)\n",
    "print(amount1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['911651', '829913', '507672', '463504', '453800', '451698', '435322', '414716', '388570', '384233', '378035', '366625', '365616', '300005', '293336', '288295', '221761']\n"
     ]
    }
   ],
   "source": [
    "amount = []\n",
    "for i in amount1:\n",
    "    amount.append(i.replace(',', ''))\n",
    "print(amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2 = []\n",
    "y = 0\n",
    "for i in amount:\n",
    "    y = float(i) /2000\n",
    "    list2.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[455.8255, 414.9565, 253.836, 231.752, 226.9, 225.849, 217.661, 207.358, 194.285, 192.1165, 189.0175, 183.3125, 182.808, 150.0025, 146.668, 144.1475, 110.8805]\n"
     ]
    }
   ],
   "source": [
    "print(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' College of Wooster ',\n",
       " ' Oberlin College ',\n",
       " ' Antioch College ',\n",
       " ' Wittenberg University ',\n",
       " ' University of Mount Union ',\n",
       " 'Kenyon College',\n",
       " ' Denison University',\n",
       " ' Ohio Northern University',\n",
       " ' Capital University ',\n",
       " ' Muskingum University ',\n",
       " ' Otterbein University',\n",
       " ' Ohio Wesleyan University',\n",
       " ' Baldwin Wallace University',\n",
       " ' Heidelberg University',\n",
       " ' Hiram College',\n",
       " ' Marietta College ',\n",
       " ' University of Mount Union ']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colleges = []\n",
    "for i in college_names:\n",
    "    colleges.append(i[1:-1].replace(',',''))\n",
    "colleges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' College of Wooster ': 455.8255, ' Oberlin College ': 414.9565, ' Antioch College ': 253.836, ' Wittenberg University ': 231.752, ' University of Mount Union ': 110.8805, 'Kenyon College': 225.849, ' Denison University': 217.661, ' Ohio Northern University': 207.358, ' Capital University ': 194.285, ' Muskingum University ': 192.1165, ' Otterbein University': 189.0175, ' Ohio Wesleyan University': 183.3125, ' Baldwin Wallace University': 182.808, ' Heidelberg University': 150.0025, ' Hiram College': 146.668, ' Marietta College ': 144.1475}\n"
     ]
    }
   ],
   "source": [
    "new_list = list(zip(colleges, list2))\n",
    "result_dict = dict(new_list)\n",
    "print(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " College of Wooster            :    455.8255\n",
      " Oberlin College               :    414.9565\n",
      " Antioch College               :    253.836\n",
      " Wittenberg University         :    231.752\n",
      " University of Mount Union     :    226.9\n",
      "Kenyon College                 :    225.849\n",
      " Denison University            :    217.661\n",
      " Ohio Northern University      :    207.358\n",
      " Capital University            :    194.285\n",
      " Muskingum University          :    192.1165\n",
      " Otterbein University          :    189.0175\n",
      " Ohio Wesleyan University      :    183.3125\n",
      " Baldwin Wallace University    :    182.808\n",
      " Heidelberg University         :    150.0025\n",
      " Hiram College                 :    146.668\n",
      " Marietta College              :    144.1475\n",
      " University of Mount Union     :    110.8805\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, j in new_list:\n",
    "    print('{:30s} {:4.1} {}'.format(i, ':', j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' College of Wooster ': 455.8255,\n",
       " ' Oberlin College ': 414.9565,\n",
       " ' Antioch College ': 253.836,\n",
       " ' Wittenberg University ': 231.752,\n",
       " 'Kenyon College': 225.849,\n",
       " ' Denison University': 217.661,\n",
       " ' Ohio Northern University': 207.358,\n",
       " ' Capital University ': 194.285,\n",
       " ' Muskingum University ': 192.1165,\n",
       " ' Otterbein University': 189.0175,\n",
       " ' Ohio Wesleyan University': 183.3125,\n",
       " ' Baldwin Wallace University': 182.808,\n",
       " ' Heidelberg University': 150.0025,\n",
       " ' Hiram College': 146.668,\n",
       " ' Marietta College ': 144.1475,\n",
       " ' University of Mount Union ': 110.8805}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from operator import itemgetter \n",
    "new_list1 = []\n",
    "for i, j in sorted(result_dict.items(), key = itemgetter(1), reverse=True):\n",
    "    new_list1.append((i, j))\n",
    "sorted_dict = dict(new_list1)\n",
    "sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " College of Wooster            :    455.8255\n",
      " Oberlin College               :    414.9565\n",
      " Antioch College               :    253.836\n",
      " Wittenberg University         :    231.752\n",
      "Kenyon College                 :    225.849\n",
      " Denison University            :    217.661\n",
      " Ohio Northern University      :    207.358\n",
      " Capital University            :    194.285\n",
      " Muskingum University          :    192.1165\n",
      " Otterbein University          :    189.0175\n",
      " Ohio Wesleyan University      :    183.3125\n",
      " Baldwin Wallace University    :    182.808\n",
      " Heidelberg University         :    150.0025\n",
      " Hiram College                 :    146.668\n",
      " Marietta College              :    144.1475\n",
      " University of Mount Union     :    110.8805\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter  \n",
    "for i, j in sorted(result_dict.items(), key = itemgetter(1), reverse=True):\n",
    "    print('{:30s} {:4.1} {}'.format(i, ':', j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
